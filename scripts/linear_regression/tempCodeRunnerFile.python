import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import os
import itertools

def linear_regression_model2(path_to_data=os.path.join(os.path.abspath(os.path.join(__file__, '..', '..', '..')), 'data')):
    # Load the prepared dataset
    data_path = os.path.join(path_to_data, "model2_dataset.csv")
    data = pd.read_csv(data_path)

    # Define features and target
    features = [
        'mean_wind_speed',
        'SpotPriceDKK',
        'BalancingPowerPriceUpDKK',
        'BalancingPowerPriceDownDKK',
        'mean_wind_power',
        'max_wind_speed_3sec',
        'max_wind_speed_10min',
    ]
    
    target = 'optimal_bid'  # The target is the optimal offering strategy

    # Check for NaN values in the target variable
    if data[target].isnull().any():
        print("NaN values found in the target variable. Removing rows with NaN values...")
        data = data.dropna(subset=[target])  # Remove rows with NaN in target

    # Check for NaN values in features
    if data[features].isnull().any().any():
        print("NaN values found in features. Removing rows with NaN values...")
        data = data.dropna(subset=features)  # Remove rows with NaN in features

    # Define features and target again after cleaning
    X = data[features]
    y = data[target]

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    best_rmse = float('inf')
    best_mae = float('inf')
    best_r2 = float('-inf')
    best_features = None

    # Evaluate all combinations of features
    for r in range(1, len(features) + 1):
        for combo in itertools.combinations(features, r):
            X_train_combo = X_train[list(combo)]
            X_test_combo = X_test[list(combo)]

            # Initialize and train the regression model
            model = LinearRegression()
            model.fit(X_train_combo, y_train)

            # Make predictions
            y_pred = model.predict(X_test_combo)

            # Evaluate the model using RMSE, MAE, and R-squared metrics
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)

            # Check if this combination gives a lower RMSE
            if rmse < best_rmse:
                best_rmse = rmse
                best_mae = mae
                best_r2 = r2
                best_features = combo

    # Print the best features and their evaluation metrics
    print(f'Best Features: {best_features}')
    print(f'Lowest Root Mean Squared Error: {best_rmse:.2f}')
    print(f'Lowest Mean Absolute Error: {best_mae:.2f}')
    print(f'Highest R^2 Score: {best_r2:.2f}')

linear_regression_model2()
